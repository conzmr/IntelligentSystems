{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A fuction that returns a dictionary of each word\n",
    "def word_feats(word):\n",
    "    return {word: True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureSet():\n",
    "    # read external file with ONE WORD PER LINE\n",
    "    text_file = open(\"positive_words.txt\", \"r\")\n",
    "    # convert IT to list\n",
    "    positive_vocab = text_file.read().lstrip('\\n').rstrip('\\n').split('\\n')\n",
    "    \n",
    "    text_file = open(\"negative_words.txt\", \"r\")\n",
    "    # convert IT to list\n",
    "    negative_vocab = text_file.read().lstrip('\\n').rstrip('\\n').split('\\n')\n",
    "    \n",
    "\n",
    "    #This will return a list of classified featuresets which are tuples\n",
    "    #Where the featuresets are dictionaries and the other a label:\n",
    "    #i.e.,(featureset(is a dict), label)\n",
    "    \n",
    "    positive_features = [(word_feats(pos), 'positive') for pos in positive_vocab]\n",
    "    negative_features = [(word_feats(neg), 'negative') for neg in negative_vocab]\n",
    "    \n",
    "    return negative_features + positive_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Sentence       \n",
      "positive   hermosa,       \n",
      "positive   gusta,         \n",
      "positive   feliz,         \n",
      "positive   gracioso,      \n",
      "positive   amar,          \n",
      "positive   satisfecho,    \n",
      "positive   calmada,       \n",
      "positive   amable,        \n",
      "positive   activa,        \n",
      "positive   energetico,    \n",
      "positive   grandioso,     \n",
      "positive   orgullosos,    \n",
      "positive   honesto,       \n",
      "positive   animada,       \n",
      "positive   esperanzado,   \n",
      "positive   relajada,      \n",
      "positive   reir,          \n",
      "positive   calida         \n",
      "negative   nadie vino,    \n",
      "negative   tampoco me gustan los tacos de puerco,\n",
      "negative   nunca compro verduras aqui,\n",
      "negative   ya no vive aqui,\n",
      "negative   no hablo mucho tampoco,\n",
      "negative   comes espinacas? no, no como espinacas nunca,\n",
      "negative   no quiero ni pizza ni pasta,\n",
      "negative   no quiero comer nada,\n",
      "negative   no hay nadie en este club,\n",
      "negative   no me gusta este libro,\n",
      "negative   mi hermano no es alto\n"
     ]
    }
   ],
   "source": [
    "train_set = featureSet()\n",
    "\n",
    "#This uses a ML-method based on Baive Bayes algorithm to train the set.\n",
    "#The training returns problabilities such as: \"what is the probability\n",
    "#of this being a positive scentance given that it contains these words...\"\n",
    "classifier = NaiveBayesClassifier.train(train_set) \n",
    " \n",
    "# Predict\n",
    "\n",
    "# read external file with ONE SENTENCE PER LINE\n",
    "text_file = open(\"positive_sentences.txt\", \"r\")\n",
    "# convert IT to list\n",
    "sentences1 = text_file.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# read external file with ONE SENTENCE PER LINE\n",
    "text_file = open(\"negative_sentences.txt\", \"r\")\n",
    "# convert IT to list\n",
    "sentences2 = text_file.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "\n",
    "# join two list of sentences\n",
    "sentences = sentences1 + sentences2\n",
    "predictions = {}\n",
    "\n",
    "#Iterate through sentences to get predictions\n",
    "for sentence in sentences:\n",
    "    #This is some very simple text preparation:\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split(' ')\n",
    "    #Store words in a dict\n",
    "    featureset = {}\n",
    "    for word in words:\n",
    "        featureset.update(word_feats(word))\n",
    "    # Use classifier to get a prediction for the sentence\n",
    "    prediction = classifier.classify(featureset)\n",
    "    #Store in dict\n",
    "    predictions[sentence] = prediction\n",
    "\n",
    "# Print predictions in a table\n",
    "print(\"{:<10} {:<15}\".format('Prediction','Sentence'))\n",
    "for k, v in predictions.items():\n",
    "    print(\"{:<10} {:<15}\".format(v, k))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
